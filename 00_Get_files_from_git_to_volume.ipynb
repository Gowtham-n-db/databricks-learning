{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "63f4fcfa-8be4-4f3e-a141-fa8de5466250",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install GitPython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "84df818a-6e9a-4db6-9e35-3afc53c438e2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%restart_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c47663b8-573f-4b4e-9a16-189bc1baef6c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from git import Repo\n",
    "import tempfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2363f653-78d4-4fe2-95cc-1fd842b983e5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "catalogs = [row.catalog for row in spark.sql(\"SHOW CATALOGS\").collect()]\n",
    "if \"mycatalog\" in catalogs:\n",
    "    schemas = [row.databaseName for row in spark.sql(\"SHOW SCHEMAS IN mycatalog\").collect()]\n",
    "    if \"myschema\" in schemas:\n",
    "        volumes = [row.volume_name for row in spark.sql(\"SHOW VOLUMES IN mycatalog.myschema\").collect()]\n",
    "        if \"myvolume\" in volumes:\n",
    "            spark.sql(\"DROP VOLUME mycatalog.myschema.myvolume\")\n",
    "        spark.sql(\"DROP SCHEMA mycatalog.myschema CASCADE\")\n",
    "    spark.sql(\"DROP CATALOG mycatalog CASCADE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a911b4e9-7a22-4ba0-b015-da1368ad0376",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "Create catalog if not exists MyCatalog;\n",
    "Create schema if not exists MyCatalog.MySchema;\n",
    "Create Volume if not exists MyCatalog.MySchema.MyVolume;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "18699ba0-4e49-4921-9c53-c57fd7185b58",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "repo_url = \"https://github.com/Gowtham-n-db/databricks-learning.git\"\n",
    "\n",
    "with tempfile.TemporaryDirectory() as repo_path:\n",
    "    # Repo.clone_from(repo_url, repo_path)\n",
    "    # Repo.clone_from(repo_url, repo_path, branch='test')\n",
    "    Repo.clone_from(repo_url, repo_path, branch='Gowtham', single_branch=True, depth=1)\n",
    "\n",
    "    file_data = {}\n",
    "    for root, dirs, files in os.walk(repo_path):\n",
    "        dirs = [item for item in dirs if item != '.git']\n",
    "        for file in files:\n",
    "            if (file.endswith('.csv') or file.endswith('.json') or file.endswith('.xml') or file.endswith('.parquet')):\n",
    "                file_path = os.path.join(root, file)\n",
    "                with open(file_path, 'rb') as f:\n",
    "                    file_data[file_path] = f.read()\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8cef7f7b-90f7-4f84-ae4c-641b1befe692",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Write the files back to the volume\n",
    "output_path = \"/Volumes/mycatalog/myschema/myvolume/repofiles\"\n",
    "\n",
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)\n",
    "\n",
    "for file_path, data in file_data.items():\n",
    "    relative_path = os.path.relpath(file_path, repo_path)\n",
    "    output_file_path = os.path.join(output_path, relative_path)\n",
    "    output_dir = os.path.dirname(output_file_path)\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    with open(output_file_path, 'wb') as f:\n",
    "        f.write(data)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 7147227793935698,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "00_Get_files_from_git_to_volume",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
