{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0e27308c-87b1-4699-b4f9-6475abcbd88e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Reading CSV data with an inferred schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e5d55285-44ed-4c29-8f7e-47fc4610febc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read CSV file into a DataFrame\n",
    "df = (spark.read\n",
    "      .format(\"csv\")\n",
    "      .option(\"header\", \"true\")\n",
    "      .load(\"../data/netflix_titles.csv\"))\n",
    "\n",
    "# Alternatively\n",
    "## If your CSV file does not have a header row\n",
    "\n",
    "df = (spark.read\n",
    "      .format(\"csv\")\n",
    "      .option(\"header\", \"false\") # When the CSV file does not have any headers\n",
    "      .load(\"/Volumes/mycatalog/myschema/myvolume/repofiles/Data-Engineering-with-Databricks-Cookbook-main/data/netflix_titles.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "52bac17e-9900-47c1-a736-640b13674e33",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Display contents of DataFrame\n",
    "df.show()\n",
    "\n",
    "# Alternatively\n",
    "\n",
    "# df.show(50)  # Display first 50 rows\n",
    "# df.show(10, truncate=False)  # Display first 10 rows without truncation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ee15cd6c-3579-47f5-9b8c-f21039a83138",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Print schema of DataFrame\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bd3e31d8-825a-445d-b038-46908ef980b3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Reading CSV data with explicit schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dca07937-7140-4d44-b4dc-29d4cdbac3c8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DateType\n",
    "\n",
    "# Define a Schema\n",
    "schema = StructType([\n",
    "    StructField(\"show_id\", StringType(), True),\n",
    "    StructField(\"type\", StringType(), True),\n",
    "    StructField(\"title\", StringType(), True),\n",
    "    StructField(\"director\", StringType(), True),\n",
    "    StructField(\"cast\", StringType(), True),\n",
    "    StructField(\"country\", StringType(), True),\n",
    "    StructField(\"date_added\", DateType(), True),\n",
    "    StructField(\"release_year\", IntegerType(), True),\n",
    "    StructField(\"rating\", StringType(), True),\n",
    "    StructField(\"duration\", StringType(), True),\n",
    "    StructField(\"listed_in\", StringType(), True),\n",
    "    StructField(\"description\", StringType(), True)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0ba3aaec-236f-4ecc-9e54-2b0a268e8d12",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read CSV file into a DataFrame\n",
    "df = (spark.read.format(\"csv\")\n",
    "      .option(\"header\", \"true\")\n",
    "      .schema(schema)\n",
    "      .load(\"/Volumes/mycatalog/myschema/myvolume/repofiles/Data-Engineering-with-Databricks-Cookbook-main/data/netflix_titles.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "89b5a141-ef9c-4940-b814-0af422c93cd1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Display contents of DataFrame\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0fb946c7-f623-4fdc-aa89-018ee1ad755b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Common issues faced while working with CSV data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d5165063-a6f9-4215-9a6c-0b248637434b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Read CSV file into a DataFrame\n",
    "df = (spark.read.format(\"csv\") \n",
    "      .option(\"header\", \"true\") \n",
    "      .option(\"nullValue\", \"null\") \n",
    "      .option(\"escapeQuotes\", \"true\") \n",
    "      .schema(schema) \n",
    "      .load(\"/Volumes/mycatalog/myschema/myvolume/repofiles/Data-Engineering-with-Databricks-Cookbook-main/data/netflix_titles.csv\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e1901305-027e-4b49-8343-ab0b5d28dc7a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Display first 5 rows of DataFrame\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5d67009a-1b33-47da-9f54-1c80adbf1618",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read CSV file into a DataFrame\n",
    "df = (spark.read\n",
    "      .format(\"csv\")\n",
    "      .option(\"header\", \"true\")\n",
    "      .option(\"nullValue\", \"null\")\n",
    "      .option(\"emptyValues\", \"\")\n",
    "      .schema(schema)\n",
    "      .load(\"/Volumes/mycatalog/myschema/myvolume/repofiles/Data-Engineering-with-Databricks-Cookbook-main/data/netflix_titles.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f0a24f08-4cff-405b-888f-31fdc2f65492",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Display first 5 rows of DataFrame\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d55f9ac7-820f-4b81-aad4-b66cf252e072",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = (spark.read.format(\"csv\")\n",
    "      .option(\"header\", \"true\")\n",
    "      .option(\"nullValue\", \"null\")\n",
    "      .option(\"dateFormat\", \"LLLL d, y\")\n",
    "      .schema(schema)\n",
    "      .load(\"/Volumes/mycatalog/myschema/myvolume/repofiles/Data-Engineering-with-Databricks-Cookbook-main/data/netflix_titles.csv\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1b2a48e7-8daa-41d4-8c17-21b9c72812a0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Display contents of DataFrame\n",
    "df.show()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "1.1 read-csv-data",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
